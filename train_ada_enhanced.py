#!/usr/bin/env python3
"""
Ada LeRobot Enhanced Perception Model ä¸“ç”¨è®­ç»ƒè„šæœ¬
ç›´æ¥è®­ç»ƒ AdaLeRobotEnhancedPerceptionModel 
"""

import os
import sys
import yaml
import h5py
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import numpy as np
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Tuple, Optional
import argparse
from tqdm import tqdm
import wandb
import logging

# å¯¼å…¥æ¨¡å‹
from ada_lerobot_enhanced_perception import AdaLeRobotEnhancedPerceptionModel

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class AdaExpandedDataset(Dataset):
    """ä¸“é—¨ä¸º ada_expanded_dataset è®¾è®¡çš„æ•°æ®é›†åŠ è½½å™¨ - å¢å¼ºç‰ˆæ”¯æŒæ•°æ®å¢å¼º
    ç°åœ¨æ”¯æŒæˆ‘ä»¬ç”Ÿæˆçš„10000æ ·æœ¬æ•°æ®é›†æ ¼å¼
    """

    def __init__(self, h5_file_path: str, window_size: int = 128, split: str = 'train',
                 augment: bool = False, augment_prob: float = 0.5):
        self.h5_file_path = h5_file_path
        self.window_size = window_size
        self.split = split
        self.augment = augment and (split == 'train')  # åªåœ¨è®­ç»ƒæ—¶è¿›è¡Œæ•°æ®å¢å¼º
        self.augment_prob = augment_prob

        # åŠ è½½æ•°æ®
        self._load_data()
        
    def _load_data(self):
        """ä»HDF5æ–‡ä»¶åŠ è½½æ•°æ® - æ”¯æŒLeRobotå¤šæ¨¡æ€æ ¼å¼å’Œæˆ‘ä»¬çš„10Kæ•°æ®é›†æ ¼å¼"""
        with h5py.File(self.h5_file_path, 'r') as f:
            logger.info(f"æ­£åœ¨åŠ è½½æ•°æ®é›†: {self.h5_file_path}")

            # æ£€æŸ¥æ•°æ®é›†æ ¼å¼
            available_keys = list(f.keys())
            logger.info(f"æ•°æ®é›†é¡¶çº§é”®: {available_keys}")

            # æ£€æŸ¥æ˜¯æ•°æ®é›†æ ¼å¼ (trajectory_0, trajectory_1, ...)
            if 'trajectory_0' in f and f.attrs.get('total_trajectories', 0) > 0:
                logger.info("æ£€æµ‹åˆ°æˆ‘ä»¬ç”Ÿæˆçš„10Kæ•°æ®é›†æ ¼å¼")
                self._load_trajectory_format(f)

            # æ”¯æŒLeRobotå¤šæ¨¡æ€æ ¼å¼
            elif 'observation' in f and 'slip_binary' in f:
                logger.info("æ£€æµ‹åˆ°LeRobotå¤šæ¨¡æ€æ ¼å¼")

                # åŠ è½½è§‚æµ‹æ•°æ®
                obs_group = f['observation']
                if 'state' in obs_group:
                    state_data = obs_group['state'][:]  # shape: (N, 128, 13)
                    # åˆ†ç¦»åŠ›å’Œå…³èŠ‚æ•°æ®
                    self.sensor_data = state_data[:, :, :6]  # å‰6ç»´æ˜¯åŠ›/æ‰­çŸ©
                    self.joint_data = state_data[:, :, 6:]   # å7ç»´æ˜¯å…³èŠ‚
                    logger.info(f"çŠ¶æ€æ•°æ®å½¢çŠ¶: {state_data.shape}")
                else:
                    raise KeyError("LeRobotæ ¼å¼ä¸­æœªæ‰¾åˆ°observation/stateæ•°æ®")

                # åŠ è½½å›¾åƒæ•°æ®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                if 'image_rgb' in obs_group:
                    self.image_data = obs_group['image_rgb'][:]
                    logger.info(f"å›¾åƒæ•°æ®å½¢çŠ¶: {self.image_data.shape}")
                else:
                    self.image_data = None
                    logger.warning("æœªæ‰¾åˆ°å›¾åƒæ•°æ®ï¼Œå°†ä½¿ç”¨éšæœºç‰¹å¾")

                # åŠ è½½æ ‡ç­¾
                self.slip_labels = f['slip_binary'][:]
                self.texture_labels = f['texture_labels'][:]

                # è·å–çº¹ç†ç±»åˆ«åç§°
                if 'texture_classes' in f.attrs:
                    self.texture_classes = [s.decode('utf-8') for s in f.attrs['texture_classes']]
                else:
                    unique_textures = np.unique(self.texture_labels)
                    self.texture_classes = [f"texture_{i}" for i in unique_textures]

                logger.info(f"çº¹ç†ç±»åˆ«: {self.texture_classes}")

            # å…¼å®¹æ—§æ ¼å¼
            elif 'data' in f and 'joint_data' in f:
                logger.info("æ£€æµ‹åˆ°ä¼ ç»Ÿæ ¼å¼")
                self.sensor_data = f['data'][:]  # ä¼ æ„Ÿå™¨æ•°æ®
                self.joint_data = f['joint_data'][:]  # å…³èŠ‚æ•°æ®
                self.image_data = None

                # åŠ¨æ€åŠ è½½æ ‡ç­¾ï¼Œå…¼å®¹å¤šç§æ ¼å¼
                if 'labels' in f and 'slip_binary' in f['labels']:
                    # æ ¼å¼1: åµŒå¥—æ ‡ç­¾æ ¼å¼ (e.g., ada_fully_labeled_dataset)
                    logger.info("æ£€æµ‹åˆ° 'labels/slip_binary' åµŒå¥—æ ¼å¼")
                    self.slip_labels = f['labels/slip_binary'][:]
                    self.texture_labels = f['labels/texture_labels'][:]
                elif 'slip_label' in f:
                    # æ ¼å¼2: æ ¹çº§æ ‡ç­¾æ ¼å¼ (æ”¹è¿›åçš„æ•°æ®é›†)
                    logger.info("æ£€æµ‹åˆ° 'slip_label' æ ¹çº§æ ¼å¼ï¼ˆæ”¹è¿›æ•°æ®é›†ï¼‰")
                    self.slip_labels = f['slip_label'][:]
                    self.texture_labels = f['texture_label'][:]
                else:
                    logger.error(f"æ— æ³•è¯†åˆ«æ ‡ç­¾æ ¼å¼ã€‚å¯ç”¨é”®: {available_keys}")
                    raise KeyError("æ— æ³•åœ¨HDF5æ–‡ä»¶ä¸­æ‰¾åˆ°å¯è¯†åˆ«çš„æ»‘ç§»æˆ–çº¹ç†æ ‡ç­¾ã€‚")
            else:
                logger.error(f"æ— æ³•è¯†åˆ«æ•°æ®é›†æ ¼å¼ã€‚å¯ç”¨é”®: {available_keys}")
                raise KeyError("æ— æ³•è¯†åˆ«æ•°æ®é›†æ ¼å¼")
            
            # æ•°æ®è´¨é‡åˆ†æ
            slip_counts = np.bincount(self.slip_labels.astype(int))
            texture_counts = np.bincount(self.texture_labels.astype(int))
            
            # è®¡ç®—å¹³è¡¡åº¦æŒ‡æ ‡
            slip_balance = min(slip_counts) / max(slip_counts) if max(slip_counts) > 0 else 0
            texture_balance = min(texture_counts) / max(texture_counts) if max(texture_counts) > 0 else 0
            
            logger.info(f"æ»‘ç§»æ ‡ç­¾åˆ†å¸ƒ: {slip_counts}")
            logger.info(f"çº¹ç†æ ‡ç­¾åˆ†å¸ƒ: {texture_counts}")
            logger.info(f"æ»‘ç§»å¹³è¡¡åº¦: {slip_balance:.3f}")
            logger.info(f"çº¹ç†å¹³è¡¡åº¦: {texture_balance:.3f}")
            
            # æ•°æ®é›†è´¨é‡è¯„ä¼°
            quality_score = 0
            if slip_balance >= 0.8:
                quality_score += 3
            elif slip_balance >= 0.6:
                quality_score += 2
            elif slip_balance >= 0.4:
                quality_score += 1
                
            if texture_balance >= 0.9:
                quality_score += 3
            elif texture_balance >= 0.7:
                quality_score += 2
            elif texture_balance >= 0.5:
                quality_score += 1
            
            if quality_score >= 5:
                logger.info("âœ… Açº§æ•°æ®é›†è´¨é‡ - é«˜å¹³è¡¡åº¦ï¼Œé€‚åˆé«˜ç²¾åº¦è®­ç»ƒ")
                self.augment_intensity = 0.3  # é™ä½å¢å¼ºå¼ºåº¦
            elif quality_score >= 3:
                logger.info("âš ï¸ Bçº§æ•°æ®é›†è´¨é‡ - ä¸­ç­‰å¹³è¡¡åº¦")
                self.augment_intensity = 0.5  # ä¸­ç­‰å¢å¼ºå¼ºåº¦
            else:
                logger.warning("âŒ Cçº§æ•°æ®é›†è´¨é‡ - ä½å¹³è¡¡åº¦ï¼Œéœ€è¦é¢å¤–å¢å¼º")
                self.augment_intensity = 0.7  # å¢åŠ å¢å¼ºå¼ºåº¦
            
            # è·å–æ•°æ®ç»Ÿè®¡
            total_windows = len(self.sensor_data)
            logger.info(f"æ€»çª—å£æ•°: {total_windows}")
            logger.info(f"ä¼ æ„Ÿå™¨æ•°æ®å½¢çŠ¶: {self.sensor_data.shape}")
            logger.info(f"å…³èŠ‚æ•°æ®å½¢çŠ¶: {self.joint_data.shape}")
            logger.info(f"æ»‘ç§»æ ‡ç­¾æ•°é‡: {len(self.slip_labels)}")
            logger.info(f"çº¹ç†æ ‡ç­¾æ•°é‡: {len(self.texture_labels)}")
            
            # åˆ†å‰²æ•°æ®é›†
            val_size = int(0.15 * total_windows)
            test_size = int(0.1 * total_windows)
            train_size = total_windows - val_size - test_size
            
            if self.split == 'train':
                self.start_idx = 0
                self.end_idx = train_size
            elif self.split == 'val':
                self.start_idx = train_size
                self.end_idx = train_size + val_size
            else:  # test
                self.start_idx = train_size + val_size
                self.end_idx = total_windows
                
            logger.info(f"{self.split} split: {self.start_idx} - {self.end_idx} ({self.end_idx - self.start_idx} samples)")

    def _load_trajectory_format(self, f):
        """åŠ è½½æˆ‘ä»¬ç”Ÿæˆçš„è½¨è¿¹æ ¼å¼æ•°æ®é›†"""
        total_trajectories = f.attrs.get('total_trajectories', 0)
        logger.info(f"åŠ è½½è½¨è¿¹æ ¼å¼æ•°æ®é›†ï¼Œæ€»è½¨è¿¹æ•°: {total_trajectories}")

        # é¢„åˆ†é…æ•°ç»„
        all_sensor_data = []
        all_joint_data = []
        all_slip_labels = []
        all_texture_labels = []

        # é£Ÿç‰©ç±»å‹åˆ°çº¹ç†æ ‡ç­¾çš„æ˜ å°„
        food_to_texture = {
            'rice': 0, 'noodles': 1, 'soup': 2, 'chicken_cube': 3,
            'tofu': 4, 'broccoli': 5
        }

        for i in range(total_trajectories):
            traj_key = f'trajectory_{i}'
            if traj_key not in f:
                continue

            traj = f[traj_key]

            # è·å–åŠ›æ•°æ® (ä½œä¸ºä¼ æ„Ÿå™¨æ•°æ®)
            forces = traj['forces']
            normal_forces = forces['total_normal_forces'][:]
            tangential_forces = forces['total_tangential_forces'][:]
            contact_count = forces['contact_count'][:]

            # ç»„åˆåŠ›æ•°æ®ä¸º6ç»´ä¼ æ„Ÿå™¨æ•°æ® (3åŠ›+3æ‰­çŸ©ï¼Œè¿™é‡Œç®€åŒ–ä¸ºnormal, tangential, contacté‡å¤)
            sensor_data = np.column_stack([
                normal_forces, tangential_forces, contact_count,
                normal_forces * 0.1, tangential_forces * 0.1, contact_count * 0.1  # æ¨¡æ‹Ÿæ‰­çŸ©
            ])

            # è·å–å…³èŠ‚æ•°æ®
            obs = traj['observations']
            joint_positions = obs['joint_positions'][:]
            joint_velocities = obs['joint_velocities'][:]

            # è·å–æ»‘ç§»æ ‡ç­¾
            slip_labels = traj['slip_labels']
            slip_detected = slip_labels['detected'][:]

            # è·å–é£Ÿç‰©ç±»å‹å¹¶è½¬æ¢ä¸ºçº¹ç†æ ‡ç­¾
            food_type = traj.attrs.get('food_type', 'rice')
            texture_label = food_to_texture.get(food_type, 0)

            # ç¡®ä¿æ•°æ®é•¿åº¦ä¸€è‡´ï¼Œå¡«å……æˆ–æˆªæ–­åˆ°window_size
            seq_len = len(sensor_data)
            if seq_len < self.window_size:
                # å¡«å……
                pad_len = self.window_size - seq_len
                sensor_data = np.pad(sensor_data, ((0, pad_len), (0, 0)), mode='edge')
                joint_positions = np.pad(joint_positions, ((0, pad_len), (0, 0)), mode='edge')
                joint_velocities = np.pad(joint_velocities, ((0, pad_len), (0, 0)), mode='edge')
                slip_detected = np.pad(slip_detected, (0, pad_len), mode='edge')
            elif seq_len > self.window_size:
                # æˆªæ–­
                sensor_data = sensor_data[:self.window_size]
                joint_positions = joint_positions[:self.window_size]
                joint_velocities = joint_velocities[:self.window_size]
                slip_detected = slip_detected[:self.window_size]

            # ç»„åˆå…³èŠ‚æ•°æ® (ä½ç½®+é€Ÿåº¦ï¼Œä½†ä¿æŒ7ç»´)
            joint_data = joint_positions  # åªä½¿ç”¨ä½ç½®ï¼Œä¿æŒ7ç»´

            # æ·»åŠ åˆ°åˆ—è¡¨
            all_sensor_data.append(sensor_data)
            all_joint_data.append(joint_data)
            # ä½¿ç”¨è½¨è¿¹çº§åˆ«çš„æ»‘ç§»æ ‡ç­¾ (å–å¹³å‡å€¼)
            all_slip_labels.append(float(np.mean(slip_detected)))
            all_texture_labels.append(texture_label)

        # è½¬æ¢ä¸ºnumpyæ•°ç»„
        self.sensor_data = np.array(all_sensor_data)  # (N, window_size, 6)
        self.joint_data = np.array(all_joint_data)    # (N, window_size, 7)
        self.slip_labels = np.array(all_slip_labels)  # (N,)
        self.texture_labels = np.array(all_texture_labels)  # (N,)

        # è®¾ç½®çº¹ç†ç±»åˆ«
        self.texture_classes = list(food_to_texture.keys())

        # å›¾åƒæ•°æ®è®¾ä¸ºNoneï¼ˆæˆ‘ä»¬çš„æ•°æ®é›†æ²¡æœ‰å›¾åƒï¼‰
        self.image_data = None

        logger.info(f"ä¼ æ„Ÿå™¨æ•°æ®å½¢çŠ¶: {self.sensor_data.shape}")
        logger.info(f"å…³èŠ‚æ•°æ®å½¢çŠ¶: {self.joint_data.shape}")
        logger.info(f"æ»‘ç§»æ ‡ç­¾æ•°é‡: {len(self.slip_labels)}")
        logger.info(f"çº¹ç†æ ‡ç­¾æ•°é‡: {len(self.texture_labels)}")
        logger.info(f"çº¹ç†ç±»åˆ«: {self.texture_classes}")

        # æ•°æ®è´¨é‡åˆ†æ
        slip_counts = np.bincount(self.slip_labels.astype(int))
        texture_counts = np.bincount(self.texture_labels.astype(int))

        # è®¡ç®—å¹³è¡¡åº¦æŒ‡æ ‡
        slip_balance = min(slip_counts) / max(slip_counts) if len(slip_counts) >= 2 and max(slip_counts) > 0 else 0
        texture_balance = min(texture_counts) / max(texture_counts) if len(texture_counts) >= 2 and max(texture_counts) > 0 else 0

        logger.info(f"æ»‘ç§»æ ‡ç­¾åˆ†å¸ƒ: {slip_counts}")
        logger.info(f"çº¹ç†æ ‡ç­¾åˆ†å¸ƒ: {texture_counts}")
        logger.info(f"æ»‘ç§»å¹³è¡¡åº¦: {slip_balance:.3f}")
        logger.info(f"çº¹ç†å¹³è¡¡åº¦: {texture_balance:.3f}")

        # æ•°æ®é›†è´¨é‡è¯„ä¼°
        quality_score = 0
        if slip_balance >= 0.8:
            quality_score += 3
        elif slip_balance >= 0.6:
            quality_score += 2
        elif slip_balance >= 0.4:
            quality_score += 1

        if texture_balance >= 0.9:
            quality_score += 3
        elif texture_balance >= 0.7:
            quality_score += 2
        elif texture_balance >= 0.5:
            quality_score += 1

        if quality_score >= 5:
            logger.info("âœ… Açº§æ•°æ®é›†è´¨é‡ - é«˜å¹³è¡¡åº¦ï¼Œé€‚åˆé«˜ç²¾åº¦è®­ç»ƒ")
            self.augment_intensity = 0.3  # é™ä½å¢å¼ºå¼ºåº¦
        elif quality_score >= 3:
            logger.info("âš ï¸ Bçº§æ•°æ®é›†è´¨é‡ - ä¸­ç­‰å¹³è¡¡åº¦")
            self.augment_intensity = 0.5  # ä¸­ç­‰å¢å¼ºå¼ºåº¦
        else:
            logger.warning("âŒ Cçº§æ•°æ®é›†è´¨é‡ - ä½å¹³è¡¡åº¦ï¼Œéœ€è¦é¢å¤–å¢å¼º")
            self.augment_intensity = 0.7  # å¢åŠ å¢å¼ºå¼ºåº¦

        # è·å–æ•°æ®ç»Ÿè®¡
        total_windows = len(self.sensor_data)
        logger.info(f"æ€»çª—å£æ•°: {total_windows}")

        # åˆ†å‰²æ•°æ®é›†
        val_size = int(0.15 * total_windows)
        test_size = int(0.1 * total_windows)
        train_size = total_windows - val_size - test_size

        if self.split == 'train':
            self.start_idx = 0
            self.end_idx = train_size
        elif self.split == 'val':
            self.start_idx = train_size
            self.end_idx = train_size + val_size
        else:  # test
            self.start_idx = train_size + val_size
            self.end_idx = total_windows

    def __len__(self):
        return self.end_idx - self.start_idx
    
    def __getitem__(self, idx):
        actual_idx = self.start_idx + idx
        
        # ä¼ æ„Ÿå™¨æ•°æ® (304, 128, 6) - åŒ…å«åŠ›æ•°æ®ç­‰
        sensor_window = self.sensor_data[actual_idx]  # (128, 6)
        
        # å…³èŠ‚æ•°æ® (304, 128, 7) 
        joint_window = self.joint_data[actual_idx]  # (128, 7)
        
        # å…ˆè½¬æ¢ä¸ºtorch tensor
        sensor_tensor = torch.tensor(sensor_window, dtype=torch.float32)  # (128, 6)
        joint_tensor = torch.tensor(joint_window, dtype=torch.float32)    # (128, 7)
        
        # æ•°æ®å¢å¼º (ä»…åœ¨è®­ç»ƒæ—¶)
        if self.augment and torch.rand(1).item() < self.augment_prob:
            sensor_tensor, joint_tensor = self._apply_augmentation(sensor_tensor, joint_tensor)
        
        # ä¿æŒæ—¶åºç»“æ„çš„ç‰¹å¾æå– - é€‚é…æ–°çš„æ¨¡å‹æ¶æ„
        # è§†è§‰ç‰¹å¾ (ä½¿ç”¨çœŸå®å›¾åƒæ•°æ®æˆ–å ä½ç¬¦)
        if hasattr(self, 'image_data') and self.image_data is not None:
            # ä½¿ç”¨çœŸå®å›¾åƒæ•°æ®ï¼Œä½†éœ€è¦è½¬æ¢ä¸ºç‰¹å¾å‘é‡
            # è¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ç®€å•çš„å…¨å±€å¹³å‡æ± åŒ–æ¥ç”Ÿæˆ512ç»´ç‰¹å¾
            image = torch.from_numpy(self.image_data[actual_idx]).float() / 255.0  # å½’ä¸€åŒ–åˆ°[0,1]
            image = image.permute(2, 0, 1)  # è½¬æ¢ä¸º(C, H, W)æ ¼å¼

            # ç®€å•çš„ç‰¹å¾æå–ï¼šå…¨å±€å¹³å‡æ± åŒ– + çº¿æ€§å˜æ¢
            # å°†(3, 224, 224)è½¬æ¢ä¸º512ç»´ç‰¹å¾å‘é‡
            pooled = torch.mean(image, dim=(1, 2))  # (3,) -> å…¨å±€å¹³å‡æ± åŒ–
            # æ‰©å±•åˆ°512ç»´
            visual_features = torch.cat([
                pooled.repeat(170),  # 3*170 = 510
                pooled[:2]           # å†åŠ 2ç»´ï¼Œæ€»å…±512ç»´
            ])
        else:
            # å ä½ç¬¦ï¼Œå®é™…é¡¹ç›®ä¸­å¯ç”¨æ‘„åƒå¤´æ•°æ®
            visual_features = torch.zeros(512)
        
        # è§¦è§‰ç‰¹å¾ = ä¼ æ„Ÿå™¨æ—¶åºæ•°æ® (batch, seq_len=128, features=6)
        tactile_features = sensor_tensor  # ä¿æŒå½¢çŠ¶ (128, 6)
        
        # åŠ›æ•°æ® = ä¼ æ„Ÿå™¨æ—¶åºæ•°æ® (batch, seq_len=128, features=6) 
        force_features = sensor_tensor  # ä¿æŒå½¢çŠ¶ (128, 6)
        
        # æœ¬ä½“æ„Ÿè§‰ç‰¹å¾ = å…³èŠ‚æ—¶åºæ•°æ® (batch, seq_len=128, features=7)
        proprioceptive_features = joint_tensor  # ä¿æŒå½¢çŠ¶ (128, 7)
        
        # æ ‡ç­¾
        slip_label = torch.tensor(float(self.slip_labels[actual_idx]), dtype=torch.float32)
        texture_label = torch.tensor(int(self.texture_labels[actual_idx]), dtype=torch.long)
        
        return {
            'visual_features': visual_features,
            'tactile_features': tactile_features,
            'force_features': force_features,
            'proprioceptive_features': proprioceptive_features,
            'slip_label': slip_label,
            'texture_label': texture_label
        }
    
    def _apply_augmentation(self, sensor_tensor, joint_tensor):
        """
        å¯¹ä¼ æ„Ÿå™¨å’Œå…³èŠ‚æ•°æ®åº”ç”¨æ•°æ®å¢å¼º
        
        Args:
            sensor_tensor: (128, 6) ä¼ æ„Ÿå™¨æ•°æ®
            joint_tensor: (128, 7) å…³èŠ‚æ•°æ®
            
        Returns:
            å¢å¼ºåçš„ä¼ æ„Ÿå™¨å’Œå…³èŠ‚æ•°æ®
        """
        # 1. é«˜æ–¯å™ªå£°å¢å¼º (é€‚ç”¨äºä¼ æ„Ÿå™¨è¯»æ•°çš„å¾®å°éšæœºå˜åŒ–)
        if torch.rand(1).item() < 0.7:  # 70%æ¦‚ç‡æ·»åŠ å™ªå£°
            noise_std = 0.02  # 2%çš„æ ‡å‡†å·®
            sensor_noise = torch.randn_like(sensor_tensor) * noise_std
            joint_noise = torch.randn_like(joint_tensor) * noise_std * 0.5  # å…³èŠ‚æ•°æ®å™ªå£°æ›´å°
            
            sensor_tensor = sensor_tensor + sensor_noise
            joint_tensor = joint_tensor + joint_noise
        
        # 2. éšæœºç¼©æ”¾ (æ¨¡æ‹Ÿä¸åŒçš„åŠ›åº¦å’Œé€Ÿåº¦)
        if torch.rand(1).item() < 0.5:  # 50%æ¦‚ç‡è¿›è¡Œç¼©æ”¾
            # ä¼ æ„Ÿå™¨æ•°æ®ç¼©æ”¾ (åŠ›/æ‰­çŸ©çš„å¼ºåº¦å˜åŒ–)
            sensor_scale = 0.85 + torch.rand(1, 6) * 0.3  # 85%-115%ç¼©æ”¾
            sensor_tensor = sensor_tensor * sensor_scale
            
            # å…³èŠ‚æ•°æ®ç¼©æ”¾ (è¿åŠ¨é€Ÿåº¦çš„å˜åŒ–)
            joint_scale = 0.9 + torch.rand(1, 7) * 0.2  # 90%-110%ç¼©æ”¾
            joint_tensor = joint_tensor * joint_scale
        
        # 3. æ—¶é—´åç§» (æ¨¡æ‹Ÿé‡‡æ ·æ—¶é—´çš„å¾®å°å˜åŒ–)
        if torch.rand(1).item() < 0.3:  # 30%æ¦‚ç‡è¿›è¡Œæ—¶é—´åç§»
            max_shift = 3  # æœ€å¤§åç§»3ä¸ªæ—¶é—´æ­¥
            shift = torch.randint(-max_shift, max_shift + 1, (1,)).item()
            
            if shift > 0:  # å‘å‰ç§»åŠ¨, ç”¨ç¬¬ä¸€ä¸ªå€¼å¡«å……å¼€å¤´
                sensor_tensor = torch.roll(sensor_tensor, shifts=shift, dims=0)
                sensor_tensor[:shift] = sensor_tensor[shift]
                joint_tensor = torch.roll(joint_tensor, shifts=shift, dims=0)
                joint_tensor[:shift] = joint_tensor[shift]
            elif shift < 0:  # å‘åç§»åŠ¨, ç”¨æœ€åä¸€ä¸ªå€¼å¡«å……ç»“å°¾
                sensor_tensor = torch.roll(sensor_tensor, shifts=shift, dims=0)
                sensor_tensor[shift:] = sensor_tensor[shift-1]
                joint_tensor = torch.roll(joint_tensor, shifts=shift, dims=0)
                joint_tensor[shift:] = joint_tensor[shift-1]
        
        # 4. éšæœºé€šé“é®ç›– (æ¨¡æ‹Ÿä¼ æ„Ÿå™¨æ•…éšœ)
        if torch.rand(1).item() < 0.2:  # 20%æ¦‚ç‡è¿›è¡Œé€šé“é®ç›–
            # éšæœºé€‰æ‹©1-2ä¸ªä¼ æ„Ÿå™¨é€šé“è¿›è¡Œé®ç›–
            num_mask_channels = torch.randint(1, 3, (1,)).item()
            if sensor_tensor.size(1) > 1:
                mask_channels = torch.randperm(sensor_tensor.size(1))[:num_mask_channels]
                for channel in mask_channels:
                    channel_mean = torch.mean(sensor_tensor[:, channel])
                    sensor_tensor[:, channel] = channel_mean
        
        return sensor_tensor, joint_tensor

    def get_window_strategy(self, is_training=True):
        """
        æ ¹æ®è®­ç»ƒ/éªŒè¯é˜¶æ®µè¿”å›çª—å£ç­–ç•¥å‚æ•°

        è®­ç»ƒé˜¶æ®µä½¿ç”¨æ— é‡å çª—å£ä»¥æé«˜è®­ç»ƒæ•ˆç‡å’Œæ•°æ®å¤šæ ·æ€§
        éªŒè¯é˜¶æ®µä½¿ç”¨50%é‡å çª—å£ä»¥è·å¾—æ›´å…¨é¢çš„è¯„ä¼°è¦†ç›–

        Args:
            is_training (bool): Trueè¡¨ç¤ºè®­ç»ƒé˜¶æ®µï¼ŒFalseè¡¨ç¤ºéªŒè¯é˜¶æ®µ

        Returns:
            dict: åŒ…å«'stride'å’Œ'overlap'å‚æ•°çš„å­—å…¸
                - stride: çª—å£æ»‘åŠ¨æ­¥é•¿
                - overlap: é‡å æ¯”ä¾‹ (0.0-1.0)
                - description: ç­–ç•¥æè¿°
        """
        if is_training:
            # è®­ç»ƒé˜¶æ®µï¼šæ— é‡å ï¼Œæé«˜è®­ç»ƒé€Ÿåº¦å’Œæ•°æ®å¤šæ ·æ€§
            return {
                'stride': self.window_size,
                'overlap': 0.0,
                'description': 'è®­ç»ƒæ¨¡å¼-æ— é‡å çª—å£'
            }
        else:
            # éªŒè¯é˜¶æ®µï¼š50%é‡å ï¼Œæä¾›æ›´å…¨é¢çš„è¯„ä¼°è¦†ç›–
            return {
                'stride': self.window_size // 2,
                'overlap': 0.5,
                'description': 'éªŒè¯æ¨¡å¼-é‡å çª—å£'
            }

class FocalLoss(nn.Module):
    """Focal Loss for addressing class imbalance"""
    def __init__(self, alpha=1, gamma=2, weight=None, reduction='mean'):
        super().__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.weight = weight
        self.reduction = reduction

    def forward(self, inputs, targets):
        ce_loss = F.cross_entropy(inputs, targets, weight=self.weight, reduction='none')
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1-pt)**self.gamma * ce_loss

        if self.reduction == 'mean':
            return focal_loss.mean()
        elif self.reduction == 'sum':
            return focal_loss.sum()
        else:
            return focal_loss

class AdaPerceptionLoss(nn.Module):
    """Adaæ„ŸçŸ¥æ¨¡å‹çš„å¤šä»»åŠ¡æŸå¤±å‡½æ•° - å¢å¼ºç‰ˆæ”¯æŒFocal Loss"""

    def __init__(self, task_weights: Dict[str, float] = None, class_weights: Dict[str, torch.Tensor] = None, use_focal_loss: bool = True):
        super().__init__()

        self.task_weights = task_weights or {
            'slip_risk_assessment': 2.0,
            'object_position_3d': 1.5,
            'grasp_quality_score': 1.5,
            'object_material_type': 1.0,
            'food_recognition': 1.0
        }

        # ç±»åˆ«æƒé‡ - è§£å†³æ•°æ®ä¸å¹³è¡¡é—®é¢˜
        self.class_weights = class_weights or {}
        self.use_focal_loss = use_focal_loss

        self.mse_loss = nn.MSELoss()

        # ä¸ºæ»‘ç§»æ£€æµ‹ä½¿ç”¨åŠ æƒBCEæŸå¤±
        slip_weights = self.class_weights.get('slip', None)
        if slip_weights is not None:
            self.bce_loss = nn.BCEWithLogitsLoss(pos_weight=slip_weights)
        else:
            self.bce_loss = nn.BCEWithLogitsLoss()

        # ä¸ºæè´¨åˆ†ç±»ä½¿ç”¨Focal Lossæˆ–åŠ æƒCEæŸå¤±
        material_weights = self.class_weights.get('material', None)
        if self.use_focal_loss:
            self.material_loss = FocalLoss(alpha=1, gamma=2, weight=material_weights)
        else:
            if material_weights is not None:
                self.material_loss = nn.CrossEntropyLoss(weight=material_weights)
            else:
                self.material_loss = nn.CrossEntropyLoss()
    
    def forward(self, outputs: Dict[str, torch.Tensor], targets: Dict[str, torch.Tensor]):
        # ç¡®ä¿total_lossæ˜¯ä¸€ä¸ªåœ¨æ­£ç¡®è®¾å¤‡ä¸Šçš„tensor
        if not outputs:
            return torch.tensor(0.0, device='cuda' if torch.cuda.is_available() else 'cpu', requires_grad=True), {}
            
        # ä»outputsä¸­è·å–ç¬¬ä¸€ä¸ªå®é™…çš„tensoræ¥ç¡®å®šè®¾å¤‡
        sample_tensor = None
        for key, value in outputs.items():
            if torch.is_tensor(value):
                sample_tensor = value
                break
            elif isinstance(value, dict):
                # å¦‚æœvalueæ˜¯å­—å…¸ï¼Œä»ä¸­æ‰¾ç¬¬ä¸€ä¸ªtensor
                for sub_key, sub_value in value.items():
                    if torch.is_tensor(sub_value):
                        sample_tensor = sub_value
                        break
                if sample_tensor is not None:
                    break
        
        if sample_tensor is None:
            # å¦‚æœæ‰¾ä¸åˆ°tensorï¼Œä½¿ç”¨é»˜è®¤è®¾å¤‡
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
        else:
            device = sample_tensor.device
            
        total_loss = torch.tensor(0.0, device=device, requires_grad=True)
        loss_dict = {}
        
        # å¤„ç†æ¨¡å‹è¾“å‡ºç»“æ„ - æ¨¡å‹è¿”å›çš„æ˜¯ {'task_outputs': {...}, ...}
        task_outputs = outputs.get('task_outputs', {})
        
        # æ»‘ç§»é£é™©è¯„ä¼°
        if 'slip_risk_assessment' in task_outputs and 'slip_label' in targets:
            slip_loss = self.bce_loss(
                task_outputs['slip_risk_assessment'].squeeze(),
                targets['slip_label']
            )
            total_loss = total_loss + self.task_weights.get('slip_risk_assessment', 1.0) * slip_loss
            loss_dict['slip_loss'] = slip_loss.item()
        
        # ç‰©ä½“æè´¨åˆ†ç±» (çº¹ç†) - ä½¿ç”¨Focal Loss
        if 'object_material_type' in task_outputs and 'texture_label' in targets:
            material_loss = self.material_loss(
                task_outputs['object_material_type'],
                targets['texture_label']
            )
            total_loss = total_loss + self.task_weights.get('object_material_type', 1.0) * material_loss
            loss_dict['material_loss'] = material_loss.item()
        
        # å…¶ä»–ä»»åŠ¡çš„æŸå¤±å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ 
        
        loss_dict['total_loss'] = total_loss.item()
        return total_loss, loss_dict

def freeze_early_layers(model, freeze_ratio=0.7):
    """
    å†»ç»“æ¨¡å‹çš„æ—©æœŸå±‚ä»¥å‡å°‘è¿‡æ‹Ÿåˆ
    
    Args:
        model: è¦å†»ç»“çš„æ¨¡å‹
        freeze_ratio: å†»ç»“å±‚çš„æ¯”ä¾‹ (0.7 = å†»ç»“å‰70%çš„å±‚)
    """
    logger.info(f"æ­£åœ¨å†»ç»“å‰ {freeze_ratio*100:.0f}% çš„æ¨¡å‹å±‚...")
    
    # è·å–æ‰€æœ‰å¯è®­ç»ƒå‚æ•°çš„å±‚
    trainable_params = [(name, param) for name, param in model.named_parameters() if param.requires_grad]
    
    # è®¡ç®—è¦å†»ç»“çš„å±‚æ•°
    freeze_count = int(len(trainable_params) * freeze_ratio)
    
    # å†»ç»“å‰ freeze_count ä¸ªå‚æ•°
    frozen_count = 0
    for name, param in trainable_params[:freeze_count]:
        param.requires_grad = False
        frozen_count += 1
    
    # ç»Ÿè®¡å†»ç»“åçš„å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params_after = sum(p.numel() for p in model.parameters() if p.requires_grad)
    
    logger.info(f"å†»ç»“äº† {frozen_count} ä¸ªå‚æ•°ç»„")
    logger.info(f"å†»ç»“å‰æ€»å‚æ•°: {total_params:,}")
    logger.info(f"å†»ç»“åå¯è®­ç»ƒå‚æ•°: {trainable_params_after:,}")
    logger.info(f"å‚æ•°å‡å°‘: {((total_params - trainable_params_after) / total_params * 100):.1f}%")

def compute_class_weights(dataset_path: str, device: torch.device):
    """è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡"""
    with h5py.File(dataset_path, 'r') as f:
        # åŠ¨æ€åŠ è½½æ ‡ç­¾ï¼Œå…¼å®¹å¤šç§æ ¼å¼
        if 'trajectory_0' in f and f.attrs.get('total_trajectories', 0) > 0:
            # æ ¼å¼0: æˆ‘ä»¬ç”Ÿæˆçš„è½¨è¿¹æ ¼å¼
            total_trajectories = f.attrs.get('total_trajectories', 0)
            slip_labels = []
            texture_labels = []

            # é£Ÿç‰©ç±»å‹åˆ°çº¹ç†æ ‡ç­¾çš„æ˜ å°„
            food_to_texture = {
                'rice': 0, 'noodles': 1, 'soup': 2, 'chicken_cube': 3,
                'tofu': 4, 'broccoli': 5
            }

            # é‡‡æ ·è½¨è¿¹è¿›è¡Œåˆ†æï¼Œç¡®ä¿å¤šæ ·æ€§
            sample_indices = np.linspace(0, total_trajectories-1, min(2000, total_trajectories), dtype=int)
            for i in sample_indices:
                traj_key = f'trajectory_{i}'
                if traj_key in f:
                    traj = f[traj_key]

                    # è·å–æ»‘ç§»æ ‡ç­¾
                    if 'slip_labels' in traj:
                        slip_detected = traj['slip_labels']['detected'][:]
                        slip_labels.append(float(np.mean(slip_detected)))

                    # è·å–é£Ÿç‰©ç±»å‹å¹¶è½¬æ¢ä¸ºçº¹ç†æ ‡ç­¾
                    food_type = traj.attrs.get('food_type', 'rice')
                    texture_label = food_to_texture.get(food_type, 0)
                    texture_labels.append(texture_label)

            slip_labels = np.array(slip_labels)
            texture_labels = np.array(texture_labels)

        elif 'observation' in f and 'slip_binary' in f:
            # æ ¼å¼1: LeRobotå¤šæ¨¡æ€æ ¼å¼
            slip_labels = f['slip_binary'][:]
            texture_labels = f['texture_labels'][:]
        elif 'labels' in f and 'slip_binary' in f['labels']:
            # æ ¼å¼2: åµŒå¥—æ ‡ç­¾æ ¼å¼
            slip_labels = f['labels/slip_binary'][:]
            texture_labels = f['labels/texture_labels'][:]
        elif 'slip_label' in f:
            # æ ¼å¼3: æ ¹çº§æ ‡ç­¾æ ¼å¼ï¼ˆæ”¹è¿›åçš„æ•°æ®é›†ï¼‰
            slip_labels = f['slip_label'][:]
            texture_labels = f['texture_label'][:]
        else:
            available_keys = list(f.keys())
            raise KeyError(f"æ— æ³•æ‰¾åˆ°å¯è¯†åˆ«çš„æ»‘ç§»æˆ–çº¹ç†æ ‡ç­¾ã€‚å¯ç”¨é”®: {available_keys}")
    
    # è®¡ç®—æ»‘ç§»æ ‡ç­¾çš„æƒé‡
    slip_counts = np.bincount(slip_labels.astype(int))
    slip_total = len(slip_labels)
    
    # æ”¹è¿›çš„æƒé‡è®¡ç®— - æ›´å¹³è¡¡çš„æƒé‡åˆ†é…
    if len(slip_counts) >= 2 and slip_counts[1] > 0:
        # ä½¿ç”¨æ”¹è¿›çš„æƒé‡è®¡ç®—æ–¹æ³•
        slip_ratio = slip_counts[1] / slip_total
        # ä¸ºå°‘æ•°ç±»è®¾ç½®æƒé‡ï¼Œä½†ä¸è¦è¿‡äºæç«¯
        slip_weights = slip_total / (2.0 * slip_counts[1]) if slip_counts[1] > 0 else 1.0
        slip_weights = min(slip_weights, 3.0)  # é™åˆ¶æœ€å¤§æƒé‡ä¸º3.0
        slip_weight_tensor = torch.tensor(slip_weights, dtype=torch.float32, device=device)
    else:
        slip_weight_tensor = torch.tensor(1.0, dtype=torch.float32, device=device)
    
    # è®¡ç®—çº¹ç†æ ‡ç­¾çš„æƒé‡
    texture_counts = np.bincount(texture_labels.astype(int))
    texture_total = len(texture_labels)
    num_classes = len(texture_counts)
    
    # æ”¹è¿›çš„çº¹ç†æƒé‡è®¡ç®—
    if num_classes > 1:
        # ä½¿ç”¨å¹³æ»‘çš„é€†é¢‘ç‡æƒé‡
        texture_weights = []
        for count in texture_counts:
            if count > 0:
                weight = texture_total / (num_classes * count)
                weight = min(weight, 2.0)  # é™åˆ¶æœ€å¤§æƒé‡
                texture_weights.append(weight)
            else:
                texture_weights.append(1.0)
        texture_weight_tensor = torch.tensor(texture_weights, dtype=torch.float32, device=device)
    else:
        texture_weight_tensor = None
    
    logger.info(f"æ»‘ç§»æ£€æµ‹æƒé‡ (æ­£ç±»): {slip_weight_tensor.item():.3f}")
    logger.info(f"çº¹ç†åˆ†ç±»æƒé‡: {texture_weights if texture_weight_tensor is not None else 'None'}")
    
    return {
        'slip': slip_weight_tensor,
        'material': texture_weight_tensor
    }

def train_epoch(model, dataloader, optimizer, criterion, device, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch"""
    model.train()
    total_loss = 0.0
    num_batches = len(dataloader)
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch}")
    
    for batch_idx, batch in enumerate(pbar):
        # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
        visual_features = batch['visual_features'].to(device)
        tactile_features = batch['tactile_features'].to(device)
        force_features = batch['force_features'].to(device)
        proprioceptive_features = batch['proprioceptive_features'].to(device)
        
        targets = {
            'slip_label': batch['slip_label'].to(device),
            'texture_label': batch['texture_label'].to(device)
        }
        
        # å‰å‘ä¼ æ’­
        optimizer.zero_grad()
        
        outputs = model(
            visual_features=visual_features,
            tactile_features=tactile_features,
            force_features=force_features,
            proprioceptive_features=proprioceptive_features,
            return_attention=False,
            return_uncertainty=True
        )
        
        # è®¡ç®—æŸå¤±
        loss, loss_dict = criterion(outputs, targets)
        
        # åå‘ä¼ æ’­
        loss.backward()
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)
        optimizer.step()
        
        total_loss += loss.item()
        
        # æ›´æ–°è¿›åº¦æ¡
        pbar.set_postfix({
            'loss': f"{loss.item():.4f}",
            'avg_loss': f"{total_loss/(batch_idx+1):.4f}"
        })
        
        # è®°å½•åˆ°WandB (å¦‚æœå·²åˆå§‹åŒ–)
        if batch_idx % 100 == 0 and hasattr(wandb, 'run') and wandb.run is not None:
            wandb.log({
                'train/batch_loss': loss.item(),
                'train/slip_loss': loss_dict.get('slip_loss', 0),
                'train/material_loss': loss_dict.get('material_loss', 0),
                'epoch': epoch,
                'batch': batch_idx
            })
    
    return total_loss / num_batches

def validate_epoch(model, dataloader, criterion, device, epoch):
    """éªŒè¯ä¸€ä¸ªepoch"""
    model.eval()
    total_loss = 0.0
    correct_slip = 0
    correct_material = 0
    total_samples = 0
    
    with torch.no_grad():
        for batch in tqdm(dataloader, desc="Validation"):
            # å°†æ•°æ®ç§»åˆ°è®¾å¤‡
            visual_features = batch['visual_features'].to(device)
            tactile_features = batch['tactile_features'].to(device)
            force_features = batch['force_features'].to(device)
            proprioceptive_features = batch['proprioceptive_features'].to(device)
            
            targets = {
                'slip_label': batch['slip_label'].to(device),
                'texture_label': batch['texture_label'].to(device)
            }
            
            # å‰å‘ä¼ æ’­
            outputs = model(
                visual_features=visual_features,
                tactile_features=tactile_features,
                force_features=force_features,
                proprioceptive_features=proprioceptive_features,
                return_attention=False,
                return_uncertainty=False
            )
            
            # è®¡ç®—æŸå¤±
            loss, loss_dict = criterion(outputs, targets)
            total_loss += loss.item()
            
            # è®¡ç®—å‡†ç¡®ç‡
            if 'task_outputs' in outputs:
                task_outputs = outputs['task_outputs']
                
                # æ»‘ç§»é£é™©è¯„ä¼°
                if 'slip_risk_assessment' in task_outputs:
                    slip_pred = torch.sigmoid(task_outputs['slip_risk_assessment']) > 0.5
                    correct_slip += (slip_pred.squeeze() == targets['slip_label']).sum().item()
                
                # æè´¨è¯†åˆ«
                if 'object_material_type' in task_outputs:
                    material_pred = task_outputs['object_material_type'].argmax(dim=1)
                    correct_material += (material_pred == targets['texture_label']).sum().item()
            
            total_samples += visual_features.size(0)
    
    avg_loss = total_loss / len(dataloader)
    slip_acc = (correct_slip / total_samples * 100) if total_samples > 0 else 0  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    material_acc = (correct_material / total_samples * 100) if total_samples > 0 else 0  # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
    
    # è®°å½•éªŒè¯ç»“æœ (å¦‚æœwandbå·²åˆå§‹åŒ–)
    if hasattr(wandb, 'run') and wandb.run is not None:
        wandb.log({
            'val/loss': avg_loss,
            'val/slip_accuracy': slip_acc,  # å·²ç»æ˜¯ç™¾åˆ†æ¯”æ ¼å¼
            'val/material_accuracy': material_acc,  # å·²ç»æ˜¯ç™¾åˆ†æ¯”æ ¼å¼
            'epoch': epoch
        })
    
    logger.info(f"Validation - Loss: {avg_loss:.4f}, Slip Acc: {slip_acc:.2f}%, Material Acc: {material_acc:.2f}%")

    return avg_loss, slip_acc, material_acc

def main():
    parser = argparse.ArgumentParser(description="Ada LeRobot Enhanced Perception Training")
    parser.add_argument("--config", type=str, default="configs/ada_enhanced_config.yaml", help="é…ç½®æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--dataset", type=str, help="æŒ‡å®šæ•°æ®é›†è·¯å¾„ï¼ˆå¯é€‰ï¼‰")
    parser.add_argument("--gpus", type=str, default="0", help="GPUè®¾å¤‡")
    parser.add_argument("--wandb", action="store_true", help="å¯ç”¨WandBæ—¥å¿—")
    
    args = parser.parse_args()
    
    # åŠ è½½é…ç½®
    try:
        with open(args.config, 'r') as f:
            config = yaml.safe_load(f)
    except FileNotFoundError:
        logger.warning(f"é…ç½®æ–‡ä»¶ {args.config} ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        config = {
            'data': {
                'source_file': '/root/workspace/assistive_mvp/9_datasets/improved/improved_ada_dataset_20250727_210943.h5',
                'window_size': 128,
                'batch_size': 32,
                'num_workers': 4,
                'use_augmentation': True,
                'augment_prob': 0.3
            },
            'model': {
                'visual_dim': 512,
                'tactile_dim': 6,         # ä¿®æ­£ï¼šè§¦è§‰æ•°æ®å®é™…æ˜¯6ç»´ç‰¹å¾(æ¥è‡ªä¼ æ„Ÿå™¨æ•°æ®)
                'force_dim': 6,           # åŠ›æ•°æ®æ˜¯6ç»´(3åŠ›+3æ‰­çŸ©)
                'proprioceptive_dim': 7,  # ä¿®æ­£ï¼šå…³èŠ‚æ•°æ®æ˜¯7ç»´
                'd_model': 256,
                'num_layers': 6,
                'num_heads': 8,
                'dropout': 0.1
            },
            'training': {
                'learning_rate': 0.001,
                'weight_decay': 1e-4,
                'epochs': 200,  # å¢åŠ åˆ°200è½®ï¼Œçº¦1å°æ—¶è®­ç»ƒ
                'patience': 25,  # å¢åŠ è€å¿ƒå€¼
                'loss_weights': {'slip': 1.0, 'texture': 1.0}
            },
            'experiment': {
                'name': 'ada_enhanced_improved_dataset',
                'output_dir': '/root/workspace/assistive_mvp/models'
            },
            'logging': {
                'use_wandb': False,
                'wandb_project': 'ada-perception'
            }
        }
    
    # ä¼˜å…ˆä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„æ•°æ®é›†è·¯å¾„
    if args.dataset:
        config['data']['source_file'] = args.dataset
        logger.info(f"ä½¿ç”¨å‘½ä»¤è¡ŒæŒ‡å®šçš„æ•°æ®é›†: {args.dataset}")
    
    # æ•°æ®é›†è·¯å¾„ä¼˜å…ˆçº§æ£€æŸ¥ - æ”¯æŒæ”¹è¿›æ•°æ®é›†
    improved_dataset_candidates = [
        config['data']['source_file'],  # é…ç½®æ–‡ä»¶æŒ‡å®šçš„è·¯å¾„
        "/root/workspace/assistive_mvp/9_datasets/improved/improved_ada_dataset_20250727_210943.h5",
        "/root/workspace/assistive_mvp/9_datasets/ada_data/ada_fully_labeled_dataset.h5"
    ]
    
    dataset_path = None
    for candidate in improved_dataset_candidates:
        if candidate and Path(candidate).exists():
            dataset_path = candidate
            break
    
    if not dataset_path:
        # å°è¯•æŸ¥æ‰¾æœ€æ–°çš„æ”¹è¿›æ•°æ®é›†
        improved_dir = Path("/root/workspace/assistive_mvp/9_datasets/improved")
        if improved_dir.exists():
            improved_files = list(improved_dir.glob("improved_ada_dataset_*.h5"))
            if improved_files:
                dataset_path = str(sorted(improved_files)[-1])  # é€‰æ‹©æœ€æ–°çš„
    
    if not dataset_path:
        logger.error("âŒ æœªæ‰¾åˆ°å¯ç”¨çš„æ•°æ®é›†æ–‡ä»¶")
        logger.info("è¯·ç¡®ä¿ä»¥ä¸‹è·¯å¾„ä¹‹ä¸€å­˜åœ¨ï¼š")
        for path in improved_dataset_candidates:
            if path:
                logger.info(f"  - {path}")
        return
    
    # æ›´æ–°é…ç½®ä¸­çš„æ•°æ®é›†è·¯å¾„
    config['data']['source_file'] = dataset_path
    logger.info(f"âœ… ä½¿ç”¨æ•°æ®é›†: {dataset_path}")
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device(f"cuda:{args.gpus}" if torch.cuda.is_available() else "cpu")
    logger.info(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åˆ†ææ•°æ®é›†è´¨é‡
    logger.info("ğŸ“Š åˆ†ææ•°æ®é›†è´¨é‡...")
    try:
        with h5py.File(dataset_path, 'r') as f:
            # æ£€æµ‹æ•°æ®é›†æ ¼å¼
            if 'trajectory_0' in f and f.attrs.get('total_trajectories', 0) > 0:
                logger.info("âœ… æ£€æµ‹åˆ°æˆ‘ä»¬ç”Ÿæˆçš„10Kè½¨è¿¹æ ¼å¼")
                # ä»è½¨è¿¹ä¸­æå–æ ‡ç­¾è¿›è¡Œåˆ†æ
                total_trajectories = f.attrs.get('total_trajectories', 0)
                slip_labels = []
                texture_labels = []

                # é£Ÿç‰©ç±»å‹åˆ°çº¹ç†æ ‡ç­¾çš„æ˜ å°„
                food_to_texture = {
                    'rice': 0, 'noodles': 1, 'soup': 2, 'chicken_cube': 3,
                    'tofu': 4, 'broccoli': 5
                }

                # é‡‡æ ·è½¨è¿¹è¿›è¡Œåˆ†æï¼Œç¡®ä¿å¤šæ ·æ€§
                sample_indices = np.linspace(0, total_trajectories-1, min(1000, total_trajectories), dtype=int)
                for i in sample_indices:
                    traj_key = f'trajectory_{i}'
                    if traj_key in f:
                        traj = f[traj_key]

                        # è·å–æ»‘ç§»æ ‡ç­¾
                        if 'slip_labels' in traj:
                            slip_detected = traj['slip_labels']['detected'][:]
                            slip_labels.append(float(np.mean(slip_detected)))

                        # è·å–é£Ÿç‰©ç±»å‹å¹¶è½¬æ¢ä¸ºçº¹ç†æ ‡ç­¾
                        food_type = traj.attrs.get('food_type', 'rice')
                        texture_label = food_to_texture.get(food_type, 0)
                        texture_labels.append(texture_label)

                slip_labels = np.array(slip_labels)
                texture_labels = np.array(texture_labels)
                dataset_format = 'trajectory'

            elif 'observation' in f and 'slip_binary' in f:
                logger.info("âœ… æ£€æµ‹åˆ°LeRobotå¤šæ¨¡æ€æ ¼å¼")
                slip_labels = f['slip_binary'][:]
                texture_labels = f['texture_labels'][:]
                dataset_format = 'lerobot'
            elif 'slip_label' in f and 'texture_label' in f:
                logger.info("âœ… æ£€æµ‹åˆ°æ”¹è¿›æ•°æ®é›†æ ¼å¼ï¼ˆæ ¹çº§æ ‡ç­¾ï¼‰")
                slip_labels = f['slip_label'][:]
                texture_labels = f['texture_label'][:]
                dataset_format = 'improved'
            elif 'labels' in f and 'slip_binary' in f['labels']:
                logger.info("âœ… æ£€æµ‹åˆ°æ ‡å‡†æ•°æ®é›†æ ¼å¼ï¼ˆåµŒå¥—æ ‡ç­¾ï¼‰")
                slip_labels = f['labels/slip_binary'][:]
                texture_labels = f['labels/texture_labels'][:]
                dataset_format = 'standard'
            else:
                available_keys = list(f.keys())
                logger.error(f"âŒ æ— æ³•è¯†åˆ«æ•°æ®é›†æ ¼å¼ã€‚å¯ç”¨é”®: {available_keys}")
                return
            
            # è´¨é‡è¯„ä¼°
            total_samples = len(slip_labels)
            slip_counts = np.bincount(slip_labels.astype(int))
            texture_counts = np.bincount(texture_labels.astype(int))
            
            slip_balance = min(slip_counts) / max(slip_counts) if len(slip_counts) >= 2 and max(slip_counts) > 0 else 0
            texture_balance = min(texture_counts) / max(texture_counts) if len(texture_counts) >= 2 and max(texture_counts) > 0 else 0
            
            logger.info(f"ğŸ“ˆ æ•°æ®é›†ç»Ÿè®¡:")
            logger.info(f"  æ€»æ ·æœ¬æ•°: {total_samples}")
            logger.info(f"  æ»‘ç§»åˆ†å¸ƒ: {dict(zip(range(len(slip_counts)), slip_counts))}")
            logger.info(f"  çº¹ç†åˆ†å¸ƒ: {dict(zip(range(len(texture_counts)), texture_counts))}")
            logger.info(f"  æ»‘ç§»å¹³è¡¡åº¦: {slip_balance:.3f}")
            logger.info(f"  çº¹ç†å¹³è¡¡åº¦: {texture_balance:.3f}")
            
            # è´¨é‡ç­‰çº§è¯„ä¼°
            quality_score = 0
            if slip_balance >= 0.6: quality_score += 3
            elif slip_balance >= 0.4: quality_score += 2
            elif slip_balance >= 0.3: quality_score += 1
            
            if texture_balance >= 0.8: quality_score += 3
            elif texture_balance >= 0.6: quality_score += 2
            elif texture_balance >= 0.4: quality_score += 1
            
            if quality_score >= 5:
                logger.info("ğŸ† Açº§æ•°æ®é›†è´¨é‡ - é¢„æœŸè®­ç»ƒç²¾åº¦>90%")
                # Açº§æ•°æ®é›†ä¼˜åŒ–é…ç½®
                config['training'].update({
                    'learning_rate': 0.0005,  # é™ä½å­¦ä¹ ç‡
                    'batch_size': min(config['data'].get('batch_size', 32), 24),  # å‡å°æ‰¹æ¬¡
                    'epochs': max(config['training'].get('epochs', 50), 60),  # å¢åŠ è®­ç»ƒè½®æ•°
                    'patience': 15
                })
                config['data']['augment_prob'] = 0.2  # é™ä½å¢å¼ºæ¦‚ç‡
            elif quality_score >= 3:
                logger.info("âš¡ Bçº§æ•°æ®é›†è´¨é‡ - é¢„æœŸè®­ç»ƒç²¾åº¦>85%")
                # Bçº§æ•°æ®é›†æ ‡å‡†é…ç½®
            else:
                logger.info("âš ï¸ Cçº§æ•°æ®é›†è´¨é‡ - å»ºè®®è¿›ä¸€æ­¥æ”¹è¿›æ•°æ®")
                # Cçº§æ•°æ®é›†é²æ£’é…ç½®
                config['training'].update({
                    'learning_rate': 0.002,   # æé«˜å­¦ä¹ ç‡
                    'weight_decay': 1e-3      # å¢å¼ºæ­£åˆ™åŒ–
                })
                config['data']['augment_prob'] = 0.5  # å¢åŠ å¢å¼ºæ¦‚ç‡
            
    except Exception as e:
        logger.error(f"æ•°æ®é›†åˆ†æå¤±è´¥: {e}")
        return
    
    # åˆå§‹åŒ–WandB
    if args.wandb and config['logging']['use_wandb']:
        wandb.init(
            project=config['logging']['wandb_project'],
            name=config['experiment']['name'],
            config=config
        )
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    output_dir = Path(config['experiment']['output_dir'])
    output_dir.mkdir(parents=True, exist_ok=True)
    
    # åˆ›å»ºæ•°æ®é›†
    train_dataset = AdaExpandedDataset(
        config['data']['source_file'], 
        window_size=config['data']['window_size'],
        split='train',
        augment=config['data'].get('use_augmentation', False),
        augment_prob=config['data'].get('augment_prob', 0.5)
    )
    val_dataset = AdaExpandedDataset(
        config['data']['source_file'],
        window_size=config['data']['window_size'], 
        split='val',
        augment=False  # éªŒè¯é›†ä¸è¿›è¡Œæ•°æ®å¢å¼º
    )
    
    # åˆ›å»ºæ•°æ®åŠ è½½å™¨
    train_loader = DataLoader(
        train_dataset,
        batch_size=config['data']['batch_size'],
        shuffle=True,
        num_workers=config['data']['num_workers'],
        pin_memory=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=config['data']['batch_size'],
        shuffle=False,
        num_workers=config['data']['num_workers'],
        pin_memory=True
    )
    
    # è·å–æ•°æ®é›†çš„çº¹ç†ç±»åˆ«æ•°
    with h5py.File(config['data']['source_file'], 'r') as f:
        if 'texture_classes' in f.attrs:
            texture_classes = [s.decode('utf-8') for s in f.attrs['texture_classes']]
            num_texture_classes = len(texture_classes)
        else:
            # ä»æ•°æ®ä¸­æ¨æ–­ç±»åˆ«æ•°
            if 'trajectory_0' in f and f.attrs.get('total_trajectories', 0) > 0:
                # è½¨è¿¹æ ¼å¼ï¼šä½¿ç”¨é£Ÿç‰©ç±»å‹æ˜ å°„
                food_to_texture = {
                    'rice': 0, 'noodles': 1, 'soup': 2, 'chicken_cube': 3,
                    'tofu': 4, 'broccoli': 5
                }
                num_texture_classes = len(food_to_texture)
            elif 'observation' in f and 'slip_binary' in f:
                texture_labels = f['texture_labels'][:]
                num_texture_classes = len(np.unique(texture_labels))
            elif 'texture_label' in f:
                texture_labels = f['texture_label'][:]
                num_texture_classes = len(np.unique(texture_labels))
            elif 'labels' in f and 'texture_labels' in f['labels']:
                texture_labels = f['labels/texture_labels'][:]
                num_texture_classes = len(np.unique(texture_labels))
            else:
                # é»˜è®¤å€¼
                num_texture_classes = 6

    logger.info(f"æ£€æµ‹åˆ° {num_texture_classes} ä¸ªçº¹ç†ç±»åˆ«")

    # åˆ›å»ºè‡ªå®šä¹‰ä»»åŠ¡é…ç½®ï¼Œä½¿ç”¨å®é™…çš„çº¹ç†ç±»åˆ«æ•°
    custom_task_configs = {
        # åŸºç¡€æ„ŸçŸ¥ä»»åŠ¡
        'object_position_3d': 3,
        'object_orientation': 4,
        'grasp_point_detection': 3,
        'grasp_quality_score': 1,
        'object_material_type': num_texture_classes,  # ä½¿ç”¨å®é™…çš„çº¹ç†ç±»åˆ«æ•°
        'object_temperature': 1,
        'object_weight': 1,
        'object_fragility': 1,
        'slip_risk_assessment': 1,
        'collision_detection': 1,

        # åŠ¨ä½œæ§åˆ¶ä»»åŠ¡
        'trajectory_planning': 7,
        'velocity_control': 7,
        'force_control': 3,
        'gripper_control': 2,
        'motion_smoothness': 1,
        'precision_requirement': 1,
        'safety_margin': 1,
        'emergency_stop_trigger': 1,
        'approach_strategy': 5,
        'retreat_strategy': 5,

        # é«˜çº§é¤é¥®ä»»åŠ¡
        'food_recognition': 20,
        'portion_estimation': 1,
        'feeding_sequence': 10,
        'utensil_selection': 5,
        'serving_technique': 8,
        'spillage_prevention': 1,
        'user_preference': 10,
        'dietary_restriction': 15,
        'meal_timing': 1,
        'satisfaction_prediction': 1
    }

    # åˆ›å»ºæ¨¡å‹ï¼Œä¼ å…¥è‡ªå®šä¹‰ä»»åŠ¡é…ç½®
    model = AdaLeRobotEnhancedPerceptionModel(
        visual_dim=config['model']['visual_dim'],
        tactile_dim=config['model']['tactile_dim'],
        force_dim=config['model']['force_dim'],
        proprioceptive_dim=config['model']['proprioceptive_dim'],
        d_model=config['model']['d_model'],
        num_layers=config['model']['num_layers'],
        num_heads=config['model']['num_heads'],
        dropout=config['model']['dropout'],
        task_configs=custom_task_configs  # ä¼ å…¥è‡ªå®šä¹‰ä»»åŠ¡é…ç½®
    ).to(device)
    
    # åº”ç”¨å±‚å†»ç»“ä»¥å‡å°‘è¿‡æ‹Ÿåˆ (æ ¹æ®é…ç½®è®¾ç½®å†»ç»“æ¯”ä¾‹)
    freeze_ratio = config.get('training', {}).get('progressive_unfreeze', {}).get('freeze_ratio', 0.7)
    freeze_early_layers(model, freeze_ratio=freeze_ratio)
    
    # è®¡ç®—æ¨¡å‹å‚æ•°æ•°é‡
    total_params = sum(p.numel() for p in model.parameters())
    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
    logger.info(f"æ¨¡å‹å‚æ•°æ€»æ•°: {total_params:,}")
    logger.info(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
    
    # è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†æ•°æ®ä¸å¹³è¡¡
    logger.info("æ­£åœ¨è®¡ç®—ç±»åˆ«æƒé‡...")
    class_weights = compute_class_weights(config['data']['source_file'], device)
    
    # åˆ›å»ºä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
    optimizer = optim.AdamW(
        model.parameters(),
        lr=config['training']['learning_rate'],
        weight_decay=config['training']['weight_decay']
    )
    
    criterion = AdaPerceptionLoss(
        task_weights=config['training']['loss_weights'],
        class_weights=class_weights,
        use_focal_loss=True  # å¯ç”¨Focal Losså¤„ç†ç±»åˆ«ä¸å¹³è¡¡
    )
    
    # ä»checkpointæ¢å¤ï¼ˆå¦‚æœæŒ‡å®šï¼‰
    start_epoch = 0
    best_val_loss = float('inf')

    # åˆå§‹åŒ–æè´¨å‡†ç¡®ç‡è·Ÿè¸ª
    model.best_material_acc = 0.0

    if config['experiment'].get('resume_from_checkpoint'):
        checkpoint_path = config['experiment']['resume_from_checkpoint']
        if Path(checkpoint_path).exists():
            logger.info(f"ä»checkpointæ¢å¤: {checkpoint_path}")
            checkpoint = torch.load(checkpoint_path, map_location=device)
            
            # åŠ è½½æ¨¡å‹æƒé‡
            model.load_state_dict(checkpoint['model_state_dict'])
            logger.info("âœ… æ¨¡å‹æƒé‡åŠ è½½æˆåŠŸ")
            
            # åŠ è½½ä¼˜åŒ–å™¨çŠ¶æ€ï¼ˆå¯é€‰ï¼Œç”¨äºç²¾è°ƒæ—¶å¯èƒ½ä¸éœ€è¦ï¼‰
            try:
                optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                logger.info("âœ… ä¼˜åŒ–å™¨çŠ¶æ€åŠ è½½æˆåŠŸ")
            except:
                logger.info("âš ï¸ ä¼˜åŒ–å™¨çŠ¶æ€åŠ è½½å¤±è´¥ï¼Œä½¿ç”¨æ–°çš„ä¼˜åŒ–å™¨çŠ¶æ€")
            
            # è®°å½•ä¹‹å‰çš„æœ€ä½³æŸå¤±å’Œæè´¨å‡†ç¡®ç‡
            best_val_loss = checkpoint.get('val_loss', float('inf'))
            model.best_material_acc = checkpoint.get('val_texture_acc', 0.0)
            start_epoch = checkpoint.get('epoch', 0) + 1

            logger.info(f"ä»epoch {start_epoch}å¼€å§‹ï¼Œä¹‹å‰æœ€ä½³éªŒè¯æŸå¤±: {best_val_loss:.4f}, æè´¨å‡†ç¡®ç‡: {model.best_material_acc:.2f}%")
        else:
            logger.warning(f"Checkpointæ–‡ä»¶ä¸å­˜åœ¨: {checkpoint_path}")
    
    # å­¦ä¹ ç‡è°ƒåº¦å™¨
    scheduler = optim.lr_scheduler.CosineAnnealingLR(
        optimizer, 
        T_max=config['training']['epochs'],
        last_epoch=start_epoch-1 if start_epoch > 0 else -1
    )
    
    # è®­ç»ƒå¾ªç¯
    patience_counter = 0
    
    for epoch in range(start_epoch, config['training']['epochs']):
        logger.info(f"å¼€å§‹è®­ç»ƒ Epoch {epoch+1}/{config['training']['epochs']}")
        
        # è®­ç»ƒ
        train_loss = train_epoch(model, train_loader, optimizer, criterion, device, epoch)
        
        # éªŒè¯
        val_loss, val_slip_acc, val_material_acc = validate_epoch(model, val_loader, criterion, device, epoch)
        
        # æ›´æ–°å­¦ä¹ ç‡
        scheduler.step()
        
        # è®°å½•åˆ°WandB (å¦‚æœå·²åˆå§‹åŒ–)
        if hasattr(wandb, 'run') and wandb.run is not None:
            wandb.log({
                'train/epoch_loss': train_loss,
                'val/epoch_loss': val_loss,
                'learning_rate': scheduler.get_last_lr()[0],
                'epoch': epoch
            })
        
        # ä¿å­˜æœ€ä½³æ¨¡å‹ - æ”¹è¿›ç­–ç•¥ï¼šåŒæ—¶è€ƒè™‘æŸå¤±å’Œæè´¨å‡†ç¡®ç‡
        save_model = False
        save_reason = ""

        # ç­–ç•¥1: éªŒè¯æŸå¤±æ”¹å–„
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            patience_counter = 0
            save_model = True
            save_reason = f"éªŒè¯æŸå¤±æ”¹å–„: {val_loss:.4f}"

        # ç­–ç•¥2: æè´¨å‡†ç¡®ç‡æ˜¾è‘—æå‡ (å³ä½¿æŸå¤±æœªæ”¹å–„)
        elif hasattr(model, 'best_material_acc'):
            if val_material_acc > model.best_material_acc + 1.0:  # é˜ˆå€¼1%ï¼ˆç°åœ¨æ˜¯ç™¾åˆ†æ¯”æ ¼å¼ï¼‰
                model.best_material_acc = val_material_acc
                patience_counter = max(0, patience_counter - 50)  # å‡å°‘è€å¿ƒè®¡æ•°
                save_model = True
                save_reason = f"æè´¨å‡†ç¡®ç‡æ˜¾è‘—æå‡: {val_material_acc:.2f}%"
        else:
            model.best_material_acc = val_material_acc
            patience_counter += 1

        if save_model:
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'val_loss': val_loss,
                'best_val_loss': best_val_loss,
                'val_slip_acc': val_slip_acc,
                'val_texture_acc': val_material_acc,
                'config': config
            }, output_dir / f"best_model_epoch_{epoch}.pth")

            logger.info(f"ä¿å­˜æœ€ä½³æ¨¡å‹ (epoch {epoch}, {save_reason})")
        else:
            patience_counter += 1
        
        # æ—©åœæ£€æŸ¥
        if patience_counter >= config['training']['patience']:
            logger.info(f"æ—©åœè§¦å‘ (patience: {config['training']['patience']})")
            break
    
    logger.info("è®­ç»ƒå®Œæˆ!")
    
    if args.wandb:
        wandb.finish()

if __name__ == "__main__":
    main()
